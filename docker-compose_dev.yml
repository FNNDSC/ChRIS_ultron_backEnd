# https://docs.docker.com/compose/yml/
# Each service defined in docker-compose.yml must specify exactly one of
# image or build. Other keys are optional, and are analogous to their
# docker run command-line counterparts.
#
# As with docker run, options specified in the Dockerfile (e.g., CMD,
# EXPOSE, VOLUME, ENV) are respected by default - you don't need to
# specify them again in docker-compose.yml.
#
# Fedora (and RHEL, CentOS) use SELinux.
# Docker needs :z volume mount options to provide a context label.
# See man docker-run

#version: '3.9'

services:
  chrisomatic:
    image: ghcr.io/fnndsc/chrisomatic:0.8.2
    volumes:
      - "./chrisomatic:/etc/chrisomatic:ro"
      - "/var/run/docker.sock:/var/run/docker.sock:rw"
    working_dir: /etc/chrisomatic
    userns_mode: host
    networks:
      - local
    depends_on:
      - chris_dev
      - chris_store
    profiles:
      - tools

  db_migrate:
    image: ${CHRISREPO}/chris:dev
    build:
      context: .
      args:
        ENVIRONMENT: local
    volumes:
      - ./chris_backend:/opt/app-root/src:z
    environment:
      - DJANGO_SETTINGS_MODULE=config.settings.local
    command: python manage.py migrate --noinput
    user: ${UID}:${GID}
    depends_on:
      chris_dev_db:
        condition: service_healthy
    networks:
      local:

  chris_dev:
    image: ${CHRISREPO}/chris:dev
    build:
      context: .
      args:
        ENVIRONMENT: local
    stdin_open: true # docker run -i
    tty: true        # docker run -t
    volumes:
      - ./chris_backend:/opt/app-root/src:z
    user: ${UID}:${GID}
    environment:
      - DJANGO_SETTINGS_MODULE=config.settings.local
    command: python manage.py runserver 0.0.0.0:8000
    ports:
      - "8000:8000"
    depends_on: 
      db_migrate:
        condition: service_completed_successfully
      swift_service:
        condition: service_started
      queue:
        condition: service_started
      chris_store:
        condition: service_started
    networks:
      local:
        aliases:
          - chrisdev.local
      remote:  # bc special automated tests worker runs within CUBE, not needed in prod
      minikube: 
    extra_hosts:
      - "${PFCONDNS:-lhost}:${PFCONIP:-127.0.0.1}"  # used only for kubernetes, not needed in prod
    labels:
      name: "ChRIS_ultron_backEnd"
      role: "Backend development server"
      org.chrisproject.role: "ChRIS_ultron_backEnd"

  worker:
    image: ${CHRISREPO}/chris:dev
    build:
      context: .
      args:
        ENVIRONMENT: local
    volumes:
      - ./chris_backend:/opt/app-root/src:z
    user: ${UID}:${GID}
    environment:
      - DJANGO_SETTINGS_MODULE=config.settings.local
      - CELERY_RDB_HOST=0.0.0.0
      - CELERY_RDB_PORT=6900
    command: celery -A core worker -c 3 -l DEBUG -Q main1,main2
    ports:
      - "6900-6905:6900-6905"
    depends_on:
      db_migrate:
        condition: service_completed_successfully
      swift_service:
        condition: service_started
      queue:
        condition: service_started
      # service also depends on pfcon service defined in swarm/docker-compose_remote.yml
    networks:
      - local
      - remote
    # When the remote ancillary service pfcon is deployed using kubernetes it can not
    # use (connect to) an external docker overlay network: remote. In that case we
    # instead use extra_hosts to let the worker know pfcon's IP address. The required
    # shell variables referenced here must then be set like this: PFCONDNS=pfcon.remote,
    # PFCONIP=<actual IP address of localhost> and REMOTENETWORK=false

    # if you are using minikube to run the kubernetes cluster, Set the environment variable in make.sh
    # MINIKUBENETWORK to true and the HOSTIP will be minikube's ip, to get this, you can run the 
    # command 'minikube ip' on the terminal
    extra_hosts:
      - "${PFCONDNS:-lhost}:${PFCONIP:-127.0.0.1}"
    labels:
      name: "ChRIS_ultron_backEnd Asynchronous Tasks Worker"
      role: "Backend development async task worker"

  worker_periodic:
    image: ${CHRISREPO}/chris:dev
    build:
      context: .
      args:
        ENVIRONMENT: local
    volumes:
      - ./chris_backend:/opt/app-root/src:z
    user: ${UID}:${GID}
    environment:
      - DJANGO_SETTINGS_MODULE=config.settings.local
    command: celery -A core worker -c 1 -l DEBUG -Q periodic
    depends_on:
      db_migrate:
        condition: service_completed_successfully
      swift_service:
        condition: service_started
      queue:
        condition: service_started
    networks:
      - local
    labels:
      name: "ChRIS_ultron_backEnd Periodic Task Worker"
      role: "Backend development periodic task worker"

  scheduler:
    image: ${CHRISREPO}/chris:dev
    build:
      context: .
      args:
        ENVIRONMENT: local
    volumes:
      - ./chris_backend:/opt/app-root/src:z
    user: ${UID}:${GID}
    environment:
      - DJANGO_SETTINGS_MODULE=config.settings.local
    command: celery -A core beat -l info --scheduler django_celery_beat.schedulers:DatabaseScheduler
    depends_on:
      db_migrate:
        condition: service_completed_successfully
      swift_service:
        condition: service_started
      queue:
        condition: service_started
    # restart until Django DB migrations are ready
    deploy:
      restart_policy:
        condition: on-failure
    networks:
      - local
    labels:
      name: "ChRIS_ultron_backEnd Periodic Tasks Scheduler"
      role: "Backend development periodic tasks scheduler"

  chris_dev_db:
    image: postgres:17
    volumes:
      - chris_dev_db_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=chris_dev
      - POSTGRES_USER=chris
      - POSTGRES_PASSWORD=Chris1234
    networks:
      - local
    labels:
      name: "ChRIS_ultron_backEnd PostgreSQL Database"
      role: "Backend development database"
    healthcheck:
      test: ["CMD", "pg_isready"]
      interval: 2s
      timeout: 4s
      retries: 3
      start_period: 60s

  queue:
    image: rabbitmq:4
    hostname: 'queue'
    volumes:
      - queue_data:/var/lib/rabbitmq
    networks:
      - local
    labels:
      name: "ChRIS_ultron_backEnd Asynchronous Task Queue"
      role: "Backend development async task queue"

  chris_store:
    image: ${STOREREPO}/chris_store
    environment:
      - DJANGO_SETTINGS_MODULE=config.settings.production
      - DJANGO_DB_MIGRATE=on
      - DJANGO_ALLOWED_HOSTS=*
      - DJANGO_SECRET_KEY="w1kxu^l=@pnsf!5piqz6!!5kdcdpo79y6jebbp+2244yjm*#+k"
      - DJANGO_CORS_ALLOW_ALL_ORIGINS=true
      - DJANGO_CORS_ALLOWED_ORIGINS=https://babymri.org
      - DJANGO_SECURE_PROXY_SSL_HEADER=
      - DJANGO_USE_X_FORWARDED_HOST=false
      - DATABASE_HOST=chris_store_db
      - DATABASE_PORT=5432
      - SWIFT_AUTH_URL=http://swift_service:8080/auth/v1.0
      - POSTGRES_DB=chris_store
      - POSTGRES_USER=chris
      - POSTGRES_PASSWORD=Chris1234
      - SWIFT_USERNAME=chris:chris1234
      - SWIFT_KEY=testing
      - SWIFT_CONTAINER_NAME=store_users
    ports:
      - "8010:8010"
    depends_on:
      - chris_store_db
      - swift_service
    networks:
      local:
        aliases:
          - chris-store.local
    labels:
      name: "ChRIS_store"
      role: "Chris store service"

  chris_store_db:
    image: postgres:17
    volumes:
      - chris_store_db_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=chris_store
      - POSTGRES_USER=chris
      - POSTGRES_PASSWORD=Chris1234
    networks:
      - local
    labels:
      name: "ChRIS_store PostgreSQL Database"
      role: "Chris store database"

  swift_service:
    image: ${SWIFTREPO}/docker-swift-onlyone
    init: true
    volumes:
      - swift_storage_dev:/srv
    environment:
      - SWIFT_USERNAME=chris:chris1234
      - SWIFT_KEY=testing
    ports:
      - "8080:8080"
    networks:
      - local
      - remote  # only needed for pfcon operating in-network
    labels:
      name: "Swift"
      role: "Swift object storage service"

  lldap:
    image: nitnelave/lldap:stable
    ports:
      - "3890:3890"
      - "17170:17170"
    volumes:
      - "lldap_data:/data"
    environment:
      - UID=10100
      - GID=10100
      - TZ=America/New_York
      - LLDAP_JWT_SECRET=super_secret_random_string
      - LLDAP_LDAP_USER_PASS=chris1234
      - LLDAP_LDAP_BASE_DN=dc=example,dc=org
    networks:
      local:

  orthanc:
    image: docker.io/jodogne/orthanc-plugins:1.12.3
    volumes:
      - ./orthanc.json:/etc/orthanc/orthanc.json:ro
      - orthanc:/var/lib/orthanc/db
    ports:
      - "4242:4242"
      - "8042:8042"
    networks:
      local:

  pfdcm:
    image: ghcr.io/fnndsc/pfdcm:3.1.2
    container_name: pfdcm
    environment:
      MAX_WORKERS: 1
    volumes:
      - ./dicom:/home/dicom:rw
      - ./pfdcm-services:/home/dicom/services:ro
      - ${STOREBASE:?}:/chris_files:rw
    ports:
      - "4005:4005"
    networks:
      local:


networks:
  local:
  remote:
    external: ${REMOTENETWORK:-true}
  minikube:
    external: ${MINIKUBENETWORK:-false}

volumes:
  chris_dev_db_data:
  chris_store_db_data:
  queue_data:
  swift_storage_dev:
  lldap_data:
  orthanc:
